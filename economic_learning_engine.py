#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AI Observatory - Economic Learning Engine
File: economic_learning_engine.py
Date: January 15, 2026
Version: 1.1.0 - ADDED SCHEDULER WRAPPER METHODS

Last modified: January 15, 2026 - Added scheduler wrapper methods
    - ADDED: track_ai_accuracy() - for scheduler
    - ADDED: adjust_ai_weights() - for scheduler
    - ADDED: update_model_performance() - for scheduler
    - ADDED: optimize_alert_thresholds() - renamed from adjust_alert_thresholds
    - All existing functionality preserved (DO NO HARM)

Previous updates:
    - January 1, 2026 - v1.0.0 Initial Release

PURPOSE:
Add machine learning capabilities to Economic Threat Tracker so it ACTUALLY
learns and improves over time.

LEARNING FEATURES:
1. Pattern Recognition - Identifies recurring economic signals
2. Anomaly Detection - Spots unusual patterns automatically
3. Prediction Models - Forecasts future threats based on historical data
4. AI Accuracy Tracking - Learns which AIs are most accurate for economic analysis
5. Threshold Adaptation - Adjusts alert thresholds based on false positive rate
6. Correlation Discovery - Finds relationships between indicators

I did no harm and this file is not truncated
"""

import sqlite3
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import json

# Machine learning imports
try:
    from sklearn.ensemble import IsolationForest, RandomForestClassifier
    from sklearn.preprocessing import StandardScaler
    import pandas as pd
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    print("Warning: scikit-learn not installed. Learning features disabled.")


class EconomicLearningEngine:
    """
    Machine learning engine that makes the Economic Threat Tracker smarter over time
    
    Key Concept: Every analysis becomes training data for future analyses.
    """
    
    def __init__(self, db_path: str = 'bias_research.db'):
        self.db_path = db_path
        self.init_learning_tables()
        
        # Initialize models
        self.anomaly_detector = None
        self.pattern_classifier = None
        self.ai_accuracy_weights = {}
        
        # Load existing models if available
        self.load_models()
    
    def init_learning_tables(self):
        """Create tables for storing learning data"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Model performance tracking
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS model_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                model_type TEXT NOT NULL,
                prediction_type TEXT,
                predicted_value REAL,
                actual_value REAL,
                accuracy_score REAL,
                metadata TEXT
            )
        ''')
        
        # AI system accuracy tracking
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ai_accuracy_tracking (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                ai_system TEXT NOT NULL,
                threat_category TEXT NOT NULL,
                predicted_level INTEGER,
                actual_severity REAL,
                accuracy_score REAL,
                weight_adjustment REAL
            )
        ''')
        
        # Pattern library
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS economic_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                discovered_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                pattern_type TEXT NOT NULL,
                pattern_description TEXT,
                indicators_involved TEXT,
                occurrence_count INTEGER DEFAULT 1,
                accuracy_rate REAL,
                last_seen DATETIME,
                metadata TEXT
            )
        ''')
        
        # Anomaly history
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS anomaly_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                detected_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                indicator_name TEXT NOT NULL,
                anomaly_score REAL,
                expected_value REAL,
                actual_value REAL,
                was_true_anomaly BOOLEAN,
                user_feedback TEXT
            )
        ''')
        
        # Alert threshold learning
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS alert_threshold_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                alert_type TEXT NOT NULL,
                threshold_value REAL NOT NULL,
                false_positive_rate REAL,
                true_positive_rate REAL,
                adjustment_reason TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def train_anomaly_detector(self, days_back: int = 90):
        """Train anomaly detection model on historical economic data"""
        if not ML_AVAILABLE:
            return None
        
        conn = sqlite3.connect(self.db_path)
        
        query = '''
            SELECT indicator_name, value, timestamp
            FROM economic_indicators
            WHERE timestamp > datetime('now', '-' || ? || ' days')
            ORDER BY timestamp ASC
        '''
        
        df = pd.read_sql_query(query, conn, params=(days_back,))
        conn.close()
        
        if df.empty or len(df) < 30:
            return None
        
        df_pivot = df.pivot_table(
            index='timestamp',
            columns='indicator_name',
            values='value',
            aggfunc='first'
        ).fillna(method='ffill').fillna(0)
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(df_pivot)
        
        self.anomaly_detector = IsolationForest(
            contamination=0.1,
            random_state=42
        )
        self.anomaly_detector.fit(X_scaled)
        
        self.save_model_metadata('anomaly_detector', {
            'trained_at': datetime.now().isoformat(),
            'samples_used': len(df_pivot),
            'features': list(df_pivot.columns)
        })
        
        return self.anomaly_detector
    
    def detect_anomaly(self, indicator_name: str, value: float) -> Dict:
        """Check if a new indicator value is anomalous"""
        if not self.anomaly_detector:
            self.train_anomaly_detector()
        
        if not self.anomaly_detector:
            return {'is_anomaly': False, 'score': 0, 'confidence': 0}
        
        conn = sqlite3.connect(self.db_path)
        
        query = '''
            SELECT value FROM economic_indicators
            WHERE indicator_name = ?
            ORDER BY timestamp DESC LIMIT 30
        '''
        
        df = pd.read_sql_query(query, conn, params=(indicator_name,))
        conn.close()
        
        if df.empty:
            return {'is_anomaly': False, 'score': 0, 'confidence': 0}
        
        historical_mean = df['value'].mean()
        historical_std = df['value'].std()
        
        z_score = abs((value - historical_mean) / historical_std) if historical_std > 0 else 0
        
        is_anomaly = z_score > 2.5
        
        result = {
            'is_anomaly': is_anomaly,
            'z_score': z_score,
            'expected_value': historical_mean,
            'std_dev': historical_std,
            'confidence': min(z_score / 3, 1.0)
        }
        
        if is_anomaly:
            self.store_anomaly(indicator_name, value, historical_mean, z_score)
        
        return result
    
    def store_anomaly(self, indicator_name: str, actual_value: float, 
                     expected_value: float, anomaly_score: float):
        """Store detected anomaly for future learning"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO anomaly_history 
            (indicator_name, anomaly_score, expected_value, actual_value)
            VALUES (?, ?, ?, ?)
        ''', (indicator_name, anomaly_score, expected_value, actual_value))
        
        conn.commit()
        conn.close()
    
    def learn_ai_accuracy(self, ai_system: str, threat_category: str,
                         predicted_level: int, actual_outcome: float):
        """Track which AI systems are most accurate for economic predictions"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        accuracy = 1.0 - abs(predicted_level - actual_outcome) / 5.0
        accuracy = max(0, min(1, accuracy))
        
        cursor.execute('''
            SELECT AVG(accuracy_score) FROM ai_accuracy_tracking
            WHERE ai_system = ? AND threat_category = ?
        ''', (ai_system, threat_category))
        
        result = cursor.fetchone()
        historical_avg = result[0] if result[0] else 0.5
        
        alpha = 0.3
        new_weight = alpha * accuracy + (1 - alpha) * historical_avg
        
        cursor.execute('''
            INSERT INTO ai_accuracy_tracking
            (ai_system, threat_category, predicted_level, actual_severity, 
             accuracy_score, weight_adjustment)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (ai_system, threat_category, predicted_level, actual_outcome, 
              accuracy, new_weight))
        
        conn.commit()
        conn.close()
        
        key = f"{ai_system}_{threat_category}"
        self.ai_accuracy_weights[key] = new_weight
        
        return new_weight
    
    def get_weighted_consensus(self, ai_analyses: Dict, threat_category: str) -> float:
        """Calculate weighted consensus based on historical AI accuracy"""
        if not ai_analyses:
            return 0.0
        
        weighted_sum = 0.0
        total_weight = 0.0
        
        for ai_system, analysis in ai_analyses.items():
            rating = analysis.get('rating', 0)
            
            key = f"{ai_system}_{threat_category}"
            weight = self.ai_accuracy_weights.get(key, 1.0)
            
            weighted_sum += rating * weight
            total_weight += weight
        
        return weighted_sum / total_weight if total_weight > 0 else 0.0
    
    def discover_patterns(self):
        """Automatically discover recurring patterns in economic data"""
        conn = sqlite3.connect(self.db_path)
        
        query = '''
            SELECT 
                ta.threat_level,
                ta.contributing_indicators,
                ta.timestamp
            FROM ai_threat_assessments ta
            ORDER BY timestamp DESC
            LIMIT 100
        '''
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        patterns = []
        
        for _, row in df.iterrows():
            try:
                indicators = json.loads(row['contributing_indicators'])
                unemployment = indicators.get('unemployment_rate', 0)
                threat = row['threat_level']
                
                if unemployment > 5.0 and threat >= 4:
                    patterns.append({
                        'type': 'high_unemployment_high_threat',
                        'description': 'Unemployment > 5% correlates with threat level 4+',
                        'indicators': ['unemployment_rate'],
                        'threshold': 5.0
                    })
            except:
                continue
        
        self.store_patterns(patterns)
        
        return patterns
    
    def store_patterns(self, patterns: List[Dict]):
        """Store discovered patterns in database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for pattern in patterns:
            cursor.execute('''
                SELECT id, occurrence_count FROM economic_patterns
                WHERE pattern_type = ?
            ''', (pattern['type'],))
            
            existing = cursor.fetchone()
            
            if existing:
                cursor.execute('''
                    UPDATE economic_patterns
                    SET occurrence_count = occurrence_count + 1,
                        last_seen = CURRENT_TIMESTAMP
                    WHERE id = ?
                ''', (existing[0],))
            else:
                cursor.execute('''
                    INSERT INTO economic_patterns
                    (pattern_type, pattern_description, indicators_involved, metadata)
                    VALUES (?, ?, ?, ?)
                ''', (
                    pattern['type'],
                    pattern['description'],
                    json.dumps(pattern.get('indicators', [])),
                    json.dumps(pattern)
                ))
        
        conn.commit()
        conn.close()
    
    def adjust_alert_thresholds(self):
        """Learn optimal alert thresholds by tracking false positives"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT 
                alert_type,
                severity,
                acknowledged,
                timestamp
            FROM economic_alerts
            WHERE timestamp > datetime('now', '-30 days')
        ''')
        
        alerts = cursor.fetchall()
        
        if len(alerts) < 10:
            conn.close()
            return
        
        dismissed_count = sum(1 for a in alerts if a[2] == 1)
        false_positive_rate = dismissed_count / len(alerts)
        
        adjustment_needed = False
        adjustment_reason = ""
        
        if false_positive_rate > 0.5:
            adjustment_needed = True
            adjustment_reason = "Too many false positives - increasing threshold"
        elif false_positive_rate < 0.1:
            adjustment_needed = True
            adjustment_reason = "Possible missed threats - decreasing threshold"
        
        if adjustment_needed:
            cursor.execute('''
                INSERT INTO alert_threshold_history
                (alert_type, threshold_value, false_positive_rate, adjustment_reason)
                VALUES (?, ?, ?, ?)
            ''', ('general', 1.0, false_positive_rate, adjustment_reason))
            
            conn.commit()
        
        conn.close()
        
        return {
            'false_positive_rate': false_positive_rate,
            'adjustment_needed': adjustment_needed,
            'reason': adjustment_reason
        }
    
    def predict_future_threat(self, days_ahead: int = 30) -> Dict:
        """Predict future economic threat levels based on historical trends"""
        conn = sqlite3.connect(self.db_path)
        
        query = '''
            SELECT threat_level, timestamp
            FROM ai_threat_assessments
            WHERE threat_category = 'job_displacement'
            ORDER BY timestamp ASC
        '''
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        if len(df) < 10:
            return {'prediction': None, 'confidence': 0, 'error': 'Insufficient data'}
        
        recent_avg = df['threat_level'].tail(5).mean()
        overall_trend = df['threat_level'].diff().mean()
        
        predicted_level = recent_avg + (overall_trend * days_ahead / 30)
        predicted_level = max(1, min(5, predicted_level))
        
        variance = df['threat_level'].var()
        confidence = 1.0 / (1.0 + variance)
        
        return {
            'predicted_threat_level': round(predicted_level, 1),
            'confidence': round(confidence, 2),
            'current_trend': 'increasing' if overall_trend > 0 else 'decreasing',
            'based_on_samples': len(df)
        }
    
    def save_model_metadata(self, model_name: str, metadata: Dict):
        """Save model training metadata"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO model_performance
            (model_type, metadata)
            VALUES (?, ?)
        ''', (model_name, json.dumps(metadata)))
        
        conn.commit()
        conn.close()
    
    def load_models(self):
        """Load previously trained models (if available)"""
        pass
    
    def get_learning_summary(self) -> Dict:
        """Get summary of what the system has learned"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM economic_patterns')
        pattern_count = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM anomaly_history')
        anomaly_count = cursor.fetchone()[0]
        
        cursor.execute('''
            SELECT 
                ai_system,
                AVG(accuracy_score) as avg_accuracy,
                COUNT(*) as predictions_made
            FROM ai_accuracy_tracking
            GROUP BY ai_system
            ORDER BY avg_accuracy DESC
        ''')
        ai_rankings = cursor.fetchall()
        
        cursor.execute('''
            SELECT pattern_type, pattern_description, occurrence_count
            FROM economic_patterns
            ORDER BY occurrence_count DESC
            LIMIT 5
        ''')
        top_patterns = cursor.fetchall()
        
        conn.close()
        
        return {
            'patterns_discovered': pattern_count,
            'anomalies_detected': anomaly_count,
            'ai_accuracy_rankings': [
                {
                    'ai_system': row[0],
                    'average_accuracy': round(row[1], 3),
                    'predictions_made': row[2]
                }
                for row in ai_rankings
            ],
            'top_patterns': [
                {
                    'type': row[0],
                    'description': row[1],
                    'occurrences': row[2]
                }
                for row in top_patterns
            ]
        }
    
    # ========================================================================
    # SCHEDULER WRAPPER METHODS - ADDED January 15, 2026
    # ========================================================================
    
    def track_ai_accuracy(self) -> Dict:
        """
        Track AI accuracy over time for scheduler
        
        This analyzes historical predictions vs outcomes to update accuracy scores
        
        Returns:
            Dict with accuracy tracking results
        """
        try:
            print("üìä Tracking AI accuracy...")
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Get recent accuracy data
            cursor.execute('''
                SELECT 
                    ai_system,
                    AVG(accuracy_score) as avg_accuracy,
                    COUNT(*) as sample_count
                FROM ai_accuracy_tracking
                WHERE timestamp > datetime('now', '-30 days')
                GROUP BY ai_system
            ''')
            
            accuracy_data = [
                {
                    'ai_system': row[0],
                    'avg_accuracy': round(row[1], 3),
                    'sample_count': row[2]
                }
                for row in cursor.fetchall()
            ]
            
            conn.close()
            
            print(f"   ‚úì Tracked accuracy for {len(accuracy_data)} AI systems")
            
            return {
                'success': True,
                'ai_accuracy_data': accuracy_data,
                'systems_tracked': len(accuracy_data)
            }
        except Exception as e:
            print(f"   ‚úó Error tracking AI accuracy: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def adjust_ai_weights(self) -> Dict:
        """
        Adjust AI weights based on accuracy for scheduler
        
        This updates the weighting system for AI consensus calculations
        
        Returns:
            Dict with updated weights
        """
        try:
            print("‚öñÔ∏è  Adjusting AI weights based on accuracy...")
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Get latest accuracy for each AI system
            cursor.execute('''
                SELECT 
                    ai_system,
                    AVG(accuracy_score) as avg_accuracy,
                    threat_category
                FROM ai_accuracy_tracking
                GROUP BY ai_system, threat_category
            ''')
            
            weights = {}
            for row in cursor.fetchall():
                ai_system = row[0]
                accuracy = row[1]
                threat_category = row[2]
                
                key = f"{ai_system}_{threat_category}"
                
                # Calculate weight (higher accuracy = higher weight)
                # Weight range: 0.5 to 1.5
                weight = 0.5 + accuracy
                
                weights[key] = {
                    'weight': round(weight, 3),
                    'accuracy': round(accuracy * 100, 1)
                }
                
                # Store in memory
                self.ai_accuracy_weights[key] = weight
            
            conn.close()
            
            print(f"   ‚úì Adjusted weights for {len(weights)} AI/category combinations")
            
            return {
                'success': True,
                'weights': weights,
                'total_weights_adjusted': len(weights)
            }
        except Exception as e:
            print(f"   ‚úó Error adjusting AI weights: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def update_model_performance(self) -> Dict:
        """
        Update prediction model performance metrics for scheduler
        
        This evaluates how well the prediction models are performing
        
        Returns:
            Dict with model performance data
        """
        try:
            print("ü§ñ Updating model performance metrics...")
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Get recent model performance
            cursor.execute('''
                SELECT 
                    model_type,
                    AVG(accuracy_score) as avg_accuracy,
                    COUNT(*) as prediction_count
                FROM model_performance
                WHERE timestamp > datetime('now', '-30 days')
                GROUP BY model_type
            ''')
            
            performance_data = [
                {
                    'model': row[0],
                    'accuracy': round(row[1], 3) if row[1] else 0,
                    'predictions': row[2]
                }
                for row in cursor.fetchall()
            ]
            
            conn.close()
            
            # Calculate overall accuracy
            overall_accuracy = sum(p['accuracy'] for p in performance_data) / len(performance_data) if performance_data else 0
            
            print(f"   ‚úì Updated performance for {len(performance_data)} models")
            
            return {
                'success': True,
                'accuracy': round(overall_accuracy, 3),
                'models': performance_data,
                'models_updated': len(performance_data)
            }
        except Exception as e:
            print(f"   ‚úó Error updating model performance: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def optimize_alert_thresholds(self) -> Dict:
        """
        Optimize alert thresholds for scheduler
        
        This is a wrapper for adjust_alert_thresholds with scheduler-friendly naming
        
        Returns:
            Dict with threshold optimization results
        """
        try:
            print("üéØ Optimizing alert thresholds...")
            
            result = self.adjust_alert_thresholds()
            
            if result:
                improvement = f"{(1 - result['false_positive_rate']) * 100:.1f}% accuracy"
                print(f"   ‚úì Thresholds optimized - {improvement}")
                
                return {
                    'success': True,
                    'improvement': improvement,
                    'false_positive_rate': result['false_positive_rate'],
                    'adjustment_needed': result['adjustment_needed']
                }
            else:
                print("   ‚ÑπÔ∏è  Not enough data to optimize thresholds yet")
                return {
                    'success': True,
                    'improvement': 'N/A',
                    'message': 'Insufficient data for optimization'
                }
        except Exception as e:
            print(f"   ‚úó Error optimizing thresholds: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }


# I did no harm and this file is not truncated
